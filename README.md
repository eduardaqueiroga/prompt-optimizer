## Prompt Optimizer com Groq API

Projeto em Python para testar e avaliar prompts em modelos de linguagem usando a Groq API. Permite:

- Enviar diferentes tipos de prompts (zero_shot, few_shot, chain_of_thought).  
- Avaliar respostas automaticamente em clareza, relev√¢ncia e precis√£o.  
- Visualizar m√©tricas m√©dias por tipo de prompt.  

üîß **Tecnologias Utilizadas**  

- Python 3.x ‚Äì Linguagem principal do projeto.  
- Pandas ‚Äì Para manipula√ß√£o e an√°lise de dados.  
- Requests ‚Äì Para chamadas HTTP √† Groq API.  
- Matplotlib ‚Äì Para visualiza√ß√£o de m√©tricas e gr√°ficos.  
- Getpass ‚Äì Para entrada segura da chave da API.  
- Groq API ‚Äì Modelo de linguagem para processamento de prompts.  

‚ö° **Requisitos**  

- Chave da Groq API v√°lida.  

üöÄ **Como usar**  

[![Abrir no Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/eduardaqueiroga/prompt-optimizer/blob/main/prompt-optimizer.ipynb)  

1. Abra o notebook no Colab clicando no bot√£o acima.  
2. Execute a c√©lula de configura√ß√£o da API.  
3. Ao ser solicitado, digite sua chave Groq API (n√£o ficar√° vis√≠vel).  
4. O notebook executar√° os prompts de teste (zero_shot, few_shot, chain_of_thought) e coletar√° os resultados.  

üìù **Configura√ß√£o de prompts**  

- `zero_shot` ‚Üí max_tokens: 300  
- `few_shot` ‚Üí max_tokens: 350  
- `chain_of_thought` ‚Üí max_tokens: 600  

Voc√™ pode alterar `max_tokens` individualmente para cada prompt, garantindo respostas completas do modelo.  

üìä **Sa√≠da**  

- DataFrame com a resposta do modelo e avalia√ß√£o autom√°tica  
- Gr√°ficos de m√©dia de notas por tipo de prompt  

‚úÖ **Observa√ß√µes**  

- O notebook foi testado com o modelo `llama-3.1-8b-instant` da Groq API  
- O uso de `getpass` garante que sua chave n√£o fique vis√≠vel  
- Se o modelo truncar a resposta, aumente `max_tokens` no prompt correspondente  

